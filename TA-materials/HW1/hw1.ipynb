"""
PixelRNN — Implementation Homework

Course: Deep Generative Models — Implementation Homework
Author: (Instructor-provided template)

This is a single-file Jupyter-style notebook (Python) designed as a self-contained
implementation assignment for PixelRNN. It contains:
- brief background
- dataset setup (binarized MNIST / CIFAR-10 options)
- model skeleton (Row LSTM / Gated PixelCNN-style masked convs suggested)
- training loop (PyTorch)
- sampling & evaluation (bits per dimension / NLL)
- exercises & deliverables

Run this file inside a Jupyter notebook or convert to .ipynb if needed.

Note: This is a template for educational purposes. Training a full PixelRNN on
CIFAR-10 to convergence may take many hours on a GPU. The code is written for
clarity and pedagogical value, not absolute runtime performance.
"""

#%% [markdown]
# PixelRNN Implementation Homework
# Objectives
# - Implement a Row LSTM PixelRNN (or a simplified masked-convolution PixelRNN)
# - Train on binarized MNIST (and optionally CIFAR-10)
# - Compute log-likelihood / bits-per-dimension (bpd)
# - Implement ancestral sampling from the autoregressive model
# - Write a short report describing architecture choices and training curves

#%% [markdown]
# Setup & Imports
import os
import math
import time
from typing import Tuple

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

#%% [markdown]
# Configuration
class Config:
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    dataset = 'MNIST'  # options: 'MNIST', 'CIFAR10'
    batch_size = 64
    img_size = 28  # for MNIST; CIFAR -> 32
    channels = 1   # MNIST:1, CIFAR:3
    lr = 2e-3
    epochs = 10
    save_dir = './pixelrnn_checkpoints'
    seed = 42

cfg = Config()
os.makedirs(cfg.save_dir, exist_ok=True)
torch.manual_seed(cfg.seed)

#%% [markdown]
# Dataset: binarized MNIST loader (recommended for initial experiments)

def get_dataloaders(cfg: Config):
    if cfg.dataset == 'MNIST':
        transform = transforms.Compose([
            transforms.ToTensor(),
            # Binarize in loader: sample from Bernoulli using pixel values
        ])
        train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
        test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

        def binarize_batch(x):
            # x is [B,1,H,W] in [0,1]
            return torch.bernoulli(x)

        train_loader = DataLoader(train, batch_size=cfg.batch_size, shuffle=True, drop_last=True)
        test_loader = DataLoader(test, batch_size=cfg.batch_size, shuffle=False, drop_last=False)
        return train_loader, test_loader, binarize_batch

    elif cfg.dataset == 'CIFAR10':
        transform = transforms.Compose([
            transforms.ToTensor(),
        ])
        train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
        test = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

        def discretize_batch(x):
            # convert to 256-level discrete values and normalize to [0,1]
            x = x * 255.0
            x = x.round() / 255.0
            return x

        train_loader = DataLoader(train, batch_size=cfg.batch_size, shuffle=True, drop_last=True)
        test_loader = DataLoader(test, batch_size=cfg.batch_size, shuffle=False, drop_last=False)
        return train_loader, test_loader, discretize_batch

    else:
        raise ValueError('Unknown dataset')

#%% [markdown]
# Model skeleton — simplified Row LSTM PixelRNN
# For pedagogical clarity we provide a simplified implementation using a masked
# convolutional stack (Gated PixelCNN style) which is easier to implement and
# captures the autoregressive masking idea. You may replace it with a Row LSTM
# implementation as an advanced exercise.

class MaskedConv2d(nn.Conv2d):
    """Conv2d with a mask on the weights to enforce autoregressive ordering.
    mask_type: 'A' for first layer (disallow center), 'B' for subsequent layers
    """
    def __init__(self, in_channels, out_channels, kernel_size, mask_type='B', stride=1, padding=0, bias=True):
        super().__init__(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)
        self.register_buffer('mask', torch.zeros_like(self.weight.data))
        kh, kw = kernel_size if isinstance(kernel_size, tuple) else (kernel_size, kernel_size)
        yc, xc = kh // 2, kw // 2
        for i in range(kh):
            for j in range(kw):
                if i < yc or (i == yc and j <= xc):
                    self.mask[:, :, i, j] = 1
        if mask_type == 'B':
            # allow center
            self.mask[:, :, yc, xc] = 1
        else:
            # mask center (type A)
            self.mask[:, :, yc, xc] = 0

    def forward(self, x):
        self.weight.data *= self.mask
        return F.conv2d(x, self.weight, self.bias, self.stride, self.padding)


class GatedPixelCNN(nn.Module):
    def __init__(self, in_channels=1, hidden=64, kernel=7, n_layers=7):
        super().__init__()
        self.input_conv = MaskedConv2d(in_channels, hidden, kernel_size=kernel, mask_type='A', padding=kernel//2)
        self.layers = nn.ModuleList([
            nn.Sequential(
                nn.ReLU(),
                MaskedConv2d(hidden, hidden, kernel_size=kernel, mask_type='B', padding=kernel//2),
                nn.ReLU(),
                nn.Conv2d(hidden, hidden, kernel_size=1)
            )
            for _ in range(n_layers)
        ])
        # final conv to predict logits for Bernoulli (or 256-way categorical for RGB)
        self.out_conv = nn.Sequential(
            nn.ReLU(),
            nn.Conv2d(hidden, in_channels, kernel_size=1)
        )

    def forward(self, x):
        # x in [B,C,H,W]
        h = self.input_conv(x)
        for layer in self.layers:
            h = h + layer(h)
        logits = self.out_conv(h)
        return logits

#%% [markdown]
# Loss & evaluation utilities

def bernoulli_nll(logits, x):
    # logits: raw scores, x: binary {0,1}
    bce = F.binary_cross_entropy_with_logits(logits, x, reduction='none')
    # sum over pixels and channels, mean over batch
    return bce.view(bce.size(0), -1).sum(1)

def bits_per_dim(nll, img_shape):
    # nll: negative log-likelihood in nats (sum over pixels). Convert to bits/dim
    # img_shape: (C,H,W)
    dims = img_shape[0] * img_shape[1] * img_shape[2]
    # convert nats -> bits: divide by ln(2)
    return (nll / math.log(2)) / dims

#%% [markdown]
# Training loop

def train_epoch(model, opt, loader, binarize_fn, cfg: Config):
    model.train()
    total_loss = 0.0
    total_bpd = 0.0
    cnt = 0
    for imgs, _ in loader:
        imgs = imgs.to(cfg.device)
        imgs = binarize_fn(imgs) if cfg.dataset == 'MNIST' else binarize_fn(imgs)
        opt.zero_grad()
        logits = model(imgs)
        nll = bernoulli_nll(logits, imgs).mean()
        nll.backward()
        opt.step()
        total_loss += nll.item()
        bpd = bits_per_dim(nll.item(), (cfg.channels, cfg.img_size, cfg.img_size))
        total_bpd += bpd
        cnt += 1
    return total_loss / cnt, total_bpd / cnt


def eval_epoch(model, loader, binarize_fn, cfg: Config):
    model.eval()
    total_nll = 0.0
    cnt = 0
    with torch.no_grad():
        for imgs, _ in loader:
            imgs = imgs.to(cfg.device)
            imgs = binarize_fn(imgs) if cfg.dataset == 'MNIST' else binarize_fn(imgs)
            logits = model(imgs)
            nll = bernoulli_nll(logits, imgs)
            total_nll += nll.sum().item()
            cnt += imgs.size(0)
    avg_nll = total_nll / cnt
    return avg_nll, bits_per_dim(avg_nll, (cfg.channels, cfg.img_size, cfg.img_size))

#%% [markdown]
# Sampling (ancestral generation)

def sample(model, cfg: Config, temperature=1.0, device=None):
    device = device or cfg.device
    model.eval()
    C, H, W = cfg.channels, cfg.img_size, cfg.img_size
    with torch.no_grad():
        x = torch.zeros((1, C, H, W), device=device)
        for i in range(H):
            for j in range(W):
                logits = model(x)
                # logits shape [1,C,H,W]
                pixel_logits = logits[:, :, i, j] / temperature
                probs = torch.sigmoid(pixel_logits)  # for binary
                sample = torch.bernoulli(probs)
                x[:, :, i, j] = sample
    return x.cpu()

#%% [markdown]
# Full run function (train + eval)

def run_training(cfg: Config):
    train_loader, test_loader, binarize_fn = get_dataloaders(cfg)
    model = GatedPixelCNN(in_channels=cfg.channels, hidden=64, kernel=7, n_layers=7).to(cfg.device)
    opt = torch.optim.Adam(model.parameters(), lr=cfg.lr)

    best_bpd = float('inf')
    for epoch in range(1, cfg.epochs + 1):
        t0 = time.time()
        train_loss, train_bpd = train_epoch(model, opt, train_loader, binarize_fn, cfg)
        val_nll, val_bpd = eval_epoch(model, test_loader, binarize_fn, cfg)
        t1 = time.time()
        print(f"Epoch {epoch}/{cfg.epochs} — train_loss: {train_loss:.4f}, train_bpd: {train_bpd:.4f} | val_bpd: {val_bpd:.4f} | time: {t1-t0:.1f}s")

        # save checkpoint
        ckpt = {
            'epoch': epoch,
            'model_state': model.state_dict(),
            'opt_state': opt.state_dict(),
            'cfg': cfg.__dict__,
        }
        torch.save(ckpt, os.path.join(cfg.save_dir, f'pixelrnn_epoch{epoch}.pt'))

        if val_bpd < best_bpd:
            best_bpd = val_bpd
            torch.save(ckpt, os.path.join(cfg.save_dir, 'pixelrnn_best.pt'))

    return model

#%% [markdown]
# Exercises & Deliverables
# 1. Implement the Row LSTM model from the original PixelRNN paper and compare
#    performance with this masked-conv variant. Report validation bits-per-dimension.
# 2. Train the masked conv model on binarized MNIST and plot training & validation bpd.
# 3. (Optional) Train on CIFAR-10 (use categorical 256-way model instead of Bernoulli).
#    For RGB images implement a 256-class softmax per pixel channel and report NLL.
# 4. Implement teacher forcing during training and compare with fully autoregressive
#    training (i.e., feeding sampled pixels). Discuss biases introduced.
# 5. Provide a short report (max 2 pages) describing architecture choices, hyperparams,
#    training curves, and include a grid of sampled images from the best checkpoint.

# Grading rubric (suggested):
# - Correctness of implementation (40%)
# - Quality of experiments & analysis (40%)
# - Code clarity & documentation (20%)

#%% [markdown]
# Notes & Hints
# - Binarized MNIST: we model p(x) with Bernoulli per pixel; use `torch.bernoulli` on
#   input images to sample binarized training targets. Evaluation should use log-likelihood
#   under the Bernoulli model (use logits -> BCE). For CIFAR-10 use discretized 256-level
#   per-channel modeling (use categorical cross-entropy).
# - PixelRNN original Row LSTM: consider implementing the row-wise LSTM scan and
#   combining vertical and horizontal LSTMs. This is more involved but yields better
#   likelihoods than masked convs in some setups.
# - For speed, use mixed precision and/or smaller hidden sizes during development.

# End of notebook template
print('PixelRNN homework template loaded. Edit configuration and run run_training(cfg)')
